{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 네이버 영화 리뷰 데이터\n",
    "# https://movie.naver.com/movie/bi/mi/basic.nhn?code=154255 : 여기서 스크래핑\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예전 버전임. scaping.ipynb 와 비교하여 어떤 차이가 있는 지 확인해보자.\n",
    "'''\n",
    "# 영화 140자평 스크래핑\n",
    "url_start = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?' \\\n",
    "      'code=154255&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=' \\\n",
    "      'false&isMileageSubscriptionReject=false&page='\n",
    "\n",
    "# 영화 리뷰가 몇 페이지까지 있는 지 확인하여 limit에 저장\n",
    "limit = 2\n",
    "        \n",
    "reviews = []\n",
    "for i in range(1, limit):\n",
    "    url = url_start + str(i)\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "    score_result = soup.find('div', class_='score_result')\n",
    "    for li in score_result.find_all('li'):\n",
    "        review = li.find('div', class_='score_reple').find('p').text\n",
    "        #print(review)\n",
    "        reviews.append(review)\n",
    "\n",
    "# 파일에 저장\n",
    "f = open(\"reviews2.txt\", \"w\")\n",
    "for r in reviews:\n",
    "    f.write(r)\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('reviews.txt', delimiter=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또는 기존에 있는 영화 리뷰 데이터 가져옴\n",
    "# https://github.com/e9t/nsmc/ \n",
    "df = pd.read_csv('ratings_train.txt', delimiter=\"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [re.sub(r\"[^가-힣A-Za-z0-9]\", \" \", str(content)) for content in df['document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reviews[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "#pos = lambda d: ['/'.join(p) for p in okt.pos(d, stem=True, norm=True)]\n",
    "pos = lambda d: ['/'.join(p) for p in okt.pos(d, stem=True, norm=True) \n",
    "                 if ('Noun' in p or 'Adjective' in p or 'Verb' in p or 'Adverb' in p) \n",
    "                 and '보다' not in p and '하다' not in p]\n",
    "reviews_tokened = [pos(doc) for doc in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokened[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(reviews_tokened[1])\n",
    "reviews_tokened[1][0].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokened[1][0].split('/')\n",
    "\n",
    "reviews_tokened_filtered = []\n",
    "for doc in reviews_tokened:\n",
    "    newdoc = [d for d in doc if d.split('/')[1] == 'Noun' or d.split('/')[1] == 'Adjective' or d.split('/')[1] == 'Adverb']\n",
    "    reviews_tokened_filtered.append(newdoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokened_filtered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(reviews_tokened_filtered)\n",
    "corpus = [dictionary.doc2bow(review) for review in reviews_tokened_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=20, id2word = dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ldamodel.print_topics(num_topics=20, num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ldamodel.show_topic(0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.show_topic(10,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.show_topic(4,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(\"TOPIC\", i)\n",
    "    for word in ldamodel.show_topic(i,15):\n",
    "        print(\"(%s %.4f)\" %(word[0], word[1]), end =\" \")\n",
    "    print()\n",
    "    print(\"---\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.get_document_topics(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "\n",
    "prepared_data = gensimvis.prepare(ldamodel, corpus, dictionary)\n",
    "pyLDAvis.display(prepared_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
